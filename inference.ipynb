{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Inference Notebook for Persian VITS (Single Speaker - Amir)\n",
    "# Setup environment\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "sys.path.append(\"vits\")\n",
    "\n",
    "import commons\n",
    "import utils\n",
    "from models import SynthesizerTrn\n",
    "from text import text_to_sequence\n",
    "from text.cleaners_fa import persian_cleaners\n",
    "from text.symbols_fa import symbols\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Load config & model checkpoint\n",
    "# Change paths as needed\n",
    "checkpoint_path = \"logs/fa_amir/G_10000.pth\"   # replace with latest G_*.pth\n",
    "config_path = \"configs/fa_single_speaker.json\"\n",
    "\n",
    "hps = utils.get_hparams_from_file(config_path)\n",
    "\n",
    "net_g = SynthesizerTrn(\n",
    "    len(symbols),\n",
    "    hps.data.filter_length // 2 + 1,\n",
    "    hps.train.segment_size // hps.data.hop_length,\n",
    "    **hps.model\n",
    ").to(device)\n",
    "\n",
    "_ = net_g.eval()\n",
    "\n",
    "_ = utils.load_checkpoint(checkpoint_path, net_g, None)\n",
    "\n",
    "# Text processing (Persian)\n",
    "def infer_text(text, noise_scale=0.667, length_scale=1.0):\n",
    "    \"\"\"Convert Persian text to sequence and synthesize speech.\"\"\"\n",
    "    text = persian_cleaners(text)\n",
    "    seq = text_to_sequence(text, hps.data.text_cleaners)\n",
    "    x = torch.LongTensor(seq).unsqueeze(0).to(device)\n",
    "    x_lengths = torch.LongTensor([x.size(1)]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_hat, *_ = net_g.infer(x, x_lengths, noise_scale=noise_scale, length_scale=length_scale)\n",
    "    return y_hat[0][0].cpu().numpy()\n",
    "\n",
    "# Run inference\n",
    "sample_texts = [\n",
    "    \"سلام! حال شما چطوره؟\",\n",
    "    \"امروز یک روز خوب برای آزمایش مدل گفتار است.\",\n",
    "    \"این یک نمونه صدا از مدل وی‌آی‌تی‌اس فارسی است.\"\n",
    "]\n",
    "\n",
    "for i, txt in enumerate(sample_texts, 1):\n",
    "    print(f\"📝 Text {i}: {txt}\")\n",
    "    audio = infer_text(txt)\n",
    "    display(ipd.Audio(audio, rate=hps.data.sampling_rate))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
