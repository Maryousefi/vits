{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference Notebook for Persian VITS (Single Speaker)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import commons\n",
    "import utils\n",
    "from data_utils import TextAudioLoader, TextAudioCollate\n",
    "from models import SynthesizerTrn\n",
    "from text import text_to_sequence\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "def get_text(text, hps):\n",
    "    \"\"\"Convert text to sequence of phoneme/character IDs.\"\"\"\n",
    "    text_norm = text_to_sequence(text, hps.data.text_cleaners)\n",
    "    if hps.data.add_blank:\n",
    "        text_norm = commons.intersperse(text_norm, 0)\n",
    "    text_norm = torch.LongTensor(text_norm)\n",
    "    return text_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persian Single Speaker Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_path = \"./configs/fa_single_speaker.json\"  # Update path as needed\n",
    "hps = utils.get_hparams_from_file(config_path)\n",
    "print(f\"Loaded config from: {config_path}\")\n",
    "print(f\"Text cleaners: {hps.data.text_cleaners}\")\n",
    "print(f\"Sampling rate: {hps.data.sampling_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import symbols after config is loaded (to ensure correct language symbols)\n",
    "from text.symbols import symbols\n",
    "print(f\"Number of symbols: {len(symbols)}\")\n",
    "print(f\"First 20 symbols: {symbols[:20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "net_g = SynthesizerTrn(\n",
    "    len(symbols),\n",
    "    hps.data.filter_length // 2 + 1,\n",
    "    hps.train.segment_size // hps.data.hop_length,\n",
    "    **hps.model).to(device)\n",
    "_ = net_g.eval()\n",
    "\n",
    "print(f\"Model initialized with {len(symbols)} symbols\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in net_g.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint\n",
    "checkpoint_path = \"./logs/fa_amir/G_10000.pth\"  # Update with your actual checkpoint path\n",
    "try:\n",
    "    _ = utils.load_checkpoint(checkpoint_path, net_g, None)\n",
    "    print(f\"Successfully loaded checkpoint: {checkpoint_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading checkpoint: {e}\")\n",
    "    print(\"Please check the checkpoint path and make sure training has produced some checkpoints.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-to-Speech Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_speech(text, noise_scale=0.667, noise_scale_w=0.8, length_scale=1.0):\n",
    "    \"\"\"Synthesize speech from Persian text.\"\"\"\n",
    "    print(f\"Input text: {text}\")\n",
    "    \n",
    "    # Convert text to sequence\n",
    "    stn_tst = get_text(text, hps)\n",
    "    print(f\"Text sequence length: {len(stn_tst)}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        x_tst = stn_tst.to(device).unsqueeze(0)\n",
    "        x_tst_lengths = torch.LongTensor([stn_tst.size(0)]).to(device)\n",
    "        \n",
    "        audio = net_g.infer(\n",
    "            x_tst, \n",
    "            x_tst_lengths, \n",
    "            noise_scale=noise_scale, \n",
    "            noise_scale_w=noise_scale_w, \n",
    "            length_scale=length_scale\n",
    "        )[0][0,0].data.cpu().float().numpy()\n",
    "    \n",
    "    print(f\"Generated audio length: {len(audio)} samples ({len(audio)/hps.data.sampling_rate:.2f} seconds)\")\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with simple Persian text\n",
    "test_texts = [\n",
    "    \"سلام دنیا\",  # Hello world\n",
    "    \"امروز روز خوبی است\",  # Today is a good day\n",
    "    \"این یک آزمایش است\",  # This is a test\n",
    "]\n",
    "\n",
    "for i, text in enumerate(test_texts, 1):\n",
    "    print(f\"\\n=== Test {i} ===\")\n",
    "    try:\n",
    "        audio = synthesize_speech(text)\n",
    "        print(\"Audio generated successfully!\")\n",
    "        \n",
    "        # Display audio player\n",
    "        ipd.display(ipd.Audio(audio, rate=hps.data.sampling_rate, normalize=False))\n",
    "        \n",
    "        # Optionally save to file\n",
    "        output_file = f\"output_sample_{i}.wav\"\n",
    "        write(output_file, hps.data.sampling_rate, audio)\n",
    "        print(f\"Saved to: {output_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating audio: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Text Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive cell for custom text input\n",
    "custom_text = \"متن فارسی خود را اینجا بنویسید\"  # Write your Persian text here\n",
    "\n",
    "print(\"Generating speech for custom text...\")\n",
    "try:\n",
    "    audio = synthesize_speech(custom_text, noise_scale=0.667, length_scale=1.0)\n",
    "    ipd.display(ipd.Audio(audio, rate=hps.data.sampling_rate, normalize=False))\n",
    "    \n",
    "    # Save custom audio\n",
    "    write(\"custom_output.wav\", hps.data.sampling_rate, audio)\n",
    "    print(\"Custom audio saved to: custom_output.wav\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different synthesis parameters\n",
    "sample_text = \"این یک متن نمونه برای آزمایش پارامترهای مختلف است\"\n",
    "\n",
    "parameters = [\n",
    "    {\"noise_scale\": 0.3, \"length_scale\": 1.0, \"name\": \"Low noise, normal speed\"},\n",
    "    {\"noise_scale\": 0.667, \"length_scale\": 1.0, \"name\": \"Default settings\"},\n",
    "    {\"noise_scale\": 1.0, \"length_scale\": 1.0, \"name\": \"High noise, normal speed\"},\n",
    "    {\"noise_scale\": 0.667, \"length_scale\": 0.8, \"name\": \"Default noise, fast speed\"},\n",
    "    {\"noise_scale\": 0.667, \"length_scale\": 1.2, \"name\": \"Default noise, slow speed\"},\n",
    "]\n",
    "\n",
    "for i, params in enumerate(parameters):\n",
    "    print(f\"\\n=== {params['name']} ===\")\n",
    "    try:\n",
    "        audio = synthesize_speech(\n",
    "            sample_text, \n",
    "            noise_scale=params['noise_scale'], \n",
    "            length_scale=params['length_scale']\n",
    "        )\n",
    "        ipd.display(ipd.Audio(audio, rate=hps.data.sampling_rate, normalize=False))\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model and configuration information\n",
    "print(\"=== Model Configuration ===\")\n",
    "print(f\"Model type: {hps.model.get('type', 'SynthesizerTrn')}\")\n",
    "print(f\"Hidden channels: {hps.model.get('hidden_channels', 'N/A')}\")\n",
    "print(f\"Filter channels: {hps.model.get('filter_channels', 'N/A')}\")\n",
    "print(f\"Number of heads: {hps.model.get('n_heads', 'N/A')}\")\n",
    "print(f\"Number of layers: {hps.model.get('n_layers', 'N/A')}\")\n",
    "print(f\"Kernel size: {hps.model.get('kernel_size', 'N/A')}\")\n",
    "\n",
    "print(\"\\n=== Data Configuration ===\")\n",
    "print(f\"Sampling rate: {hps.data.sampling_rate}\")\n",
    "print(f\"Filter length: {hps.data.filter_length}\")\n",
    "print(f\"Hop length: {hps.data.hop_length}\")\n",
    "print(f\"Win length: {hps.data.win_length}\")\n",
    "print(f\"Text cleaners: {hps.data.text_cleaners}\")\n",
    "print(f\"Add blank: {hps.data.get('add_blank', False)}\")\n",
    "\n",
    "print(\"\\n=== Symbol Set ===\")\n",
    "print(f\"Total symbols: {len(symbols)}\")\n",
    "print(f\"Symbols: {symbols}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
